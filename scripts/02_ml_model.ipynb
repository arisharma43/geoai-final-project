{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa11894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# POPULATION GROWTH PREDICTION FOR HARRIS COUNTY CENSUS TRACTS\n",
    "# ==============================================================================\n",
    "# GOAL: Predict population growth rate (% change 2010â†’2021) for each census tract\n",
    "# TYPE: Regression Problem\n",
    "# OUTPUT: Continuous value representing % population change\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332affe8",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Data\n",
    "\n",
    "Load the prepared CSV file that contains:\n",
    "\n",
    "- Census tract identifiers\n",
    "- Population data (2010, 2015, 2021)\n",
    "- Flood risk metrics (% in AE zone, % in X zone, etc.)\n",
    "- Elevation features (mean, min, max, slope, REM)\n",
    "- Water proximity (distance to nearest water body)\n",
    "- Flow accumulation metrics\n",
    "- Spatial features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53754cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared dataset\n",
    "# This CSV should be created from your data processing script (01_data_exploration.ipynb)\n",
    "df = pd.read_csv(\"../data/processed/census_tracts_features.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa75ce8",
   "metadata": {},
   "source": [
    "## 2. Create Target Variable (Y)\n",
    "\n",
    "**Target**: % Population Change from 2010 to 2021\n",
    "\n",
    "Formula: `((pop_2021 - pop_2010) / pop_2010) * 100`\n",
    "\n",
    "This represents the percentage growth or decline over the ~11 year period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b27f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate population change percentage\n",
    "# Assumes columns: pop_2010, pop_2021 exist in the dataframe\n",
    "df[\"pop_change_pct\"] = ((df[\"pop_2021\"] - df[\"pop_2010\"]) / df[\"pop_2010\"]) * 100\n",
    "\n",
    "# Handle edge cases\n",
    "# Remove tracts with zero population in 2010 (division by zero)\n",
    "df = df[df[\"pop_2010\"] > 0].copy()\n",
    "\n",
    "# Remove extreme outliers (optional - adjust thresholds as needed)\n",
    "# This removes tracts with unrealistic growth (e.g., >500% or <-99%)\n",
    "df = df[(df[\"pop_change_pct\"] > -99) & (df[\"pop_change_pct\"] < 500)].copy()\n",
    "\n",
    "print(f\"Dataset shape after cleaning: {df.shape}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(df[\"pop_change_pct\"].describe())\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df[\"pop_change_pct\"], bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Population Change (%)\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Distribution of Population Change 2010-2021\")\n",
    "axes[0].axvline(0, color=\"red\", linestyle=\"--\", label=\"No Change\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].boxplot(df[\"pop_change_pct\"])\n",
    "axes[1].set_ylabel(\"Population Change (%)\")\n",
    "axes[1].set_title(\"Boxplot of Population Change\")\n",
    "axes[1].axhline(0, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGrowth categories:\")\n",
    "print(f\"  Declining (< -5%): {len(df[df['pop_change_pct'] < -5])} tracts\")\n",
    "print(\n",
    "    f\"  Stable (-5% to 5%): {len(df[(df['pop_change_pct'] >= -5) & (df['pop_change_pct'] <= 5)])} tracts\"\n",
    ")\n",
    "print(f\"  Growing (> 5%): {len(df[df['pop_change_pct'] > 5])} tracts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c82f81",
   "metadata": {},
   "source": [
    "## 3. Define Feature Sets (X)\n",
    "\n",
    "**Feature Categories:**\n",
    "\n",
    "1. **Flood Risk Features:**\n",
    "\n",
    "   - `pct_in_AE`: % of tract in high-risk AE flood zone\n",
    "   - `pct_in_X`: % of tract in low-risk X zone (outside 500-year floodplain)\n",
    "   - `pct_in_VE`: % in coastal high velocity zone (if applicable)\n",
    "   - `pct_in_floodway`: % in regulatory floodway\n",
    "\n",
    "2. **Elevation & Topography:**\n",
    "\n",
    "   - `elev_mean`: Mean elevation (meters)\n",
    "   - `elev_min`: Minimum elevation\n",
    "   - `elev_max`: Maximum elevation\n",
    "   - `elev_std`: Elevation standard deviation (terrain roughness)\n",
    "   - `slope_mean`: Mean terrain slope\n",
    "   - `slope_max`: Maximum slope\n",
    "   - `pct_low_slope`: % of area with slope < 2 degrees (flat/flood-prone)\n",
    "\n",
    "3. **Hydrological:**\n",
    "\n",
    "   - `dist_water_m`: Distance to nearest water body (meters)\n",
    "   - `flowacc_mean`: Mean flow accumulation (drainage potential)\n",
    "   - `rem_mean`: Relative Elevation Model value (height above nearest drainage)\n",
    "\n",
    "4. **Baseline Demographics:**\n",
    "\n",
    "   - `pop_2010`: Initial population (baseline)\n",
    "   - `pop_density_2010`: Population density in 2010 (people/sq km)\n",
    "   - `area_sq_km`: Tract area\n",
    "\n",
    "5. **Spatial Features (optional):**\n",
    "   - `centroid_lat`: Latitude of tract centroid\n",
    "   - `centroid_lon`: Longitude of tract centroid\n",
    "   - `dist_to_downtown_km`: Distance to downtown Houston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "# Adjust these based on what's actually in your processed CSV\n",
    "feature_cols = [\n",
    "    # Flood risk\n",
    "    \"pct_in_AE\",\n",
    "    \"pct_in_X\",\n",
    "    \"pct_in_floodway\",\n",
    "    # Elevation & topography\n",
    "    \"elev_mean\",\n",
    "    \"elev_min\",\n",
    "    \"elev_std\",\n",
    "    \"slope_mean\",\n",
    "    \"slope_max\",\n",
    "    \"pct_low_slope\",\n",
    "    # Hydrological\n",
    "    \"dist_water_m\",\n",
    "    \"flowacc_mean\",\n",
    "    \"rem_mean\",\n",
    "    # Baseline demographics\n",
    "    \"pop_2010\",\n",
    "    \"pop_density_2010\",\n",
    "    \"area_sq_km\",\n",
    "    # Spatial (optional)\n",
    "    # 'centroid_lat',\n",
    "    # 'centroid_lon',\n",
    "    # 'dist_to_downtown_km'\n",
    "]\n",
    "\n",
    "# Check which features are actually available\n",
    "available_features = [col for col in feature_cols if col in df.columns]\n",
    "missing_features = [col for col in feature_cols if col not in df.columns]\n",
    "\n",
    "print(f\"Available features ({len(available_features)}): {available_features}\")\n",
    "print(f\"\\nMissing features ({len(missing_features)}): {missing_features}\")\n",
    "\n",
    "# Use only available features\n",
    "X = df[available_features].copy()\n",
    "y = df[\"pop_change_pct\"].copy()\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Check for missing values in features\n",
    "print(f\"\\nMissing values in features:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Option 1: Drop rows with any missing values\n",
    "# X = X.dropna()\n",
    "# y = y[X.index]\n",
    "\n",
    "# Option 2: Fill with median (more common for ML)\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"\\nFilling missing values with column medians...\")\n",
    "    X = X.fillna(X.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca84a18",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Understand relationships between features and target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf86fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_data = pd.concat([X, y], axis=1)\n",
    "corr_matrix = correlation_data.corr()\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.title(\"Feature Correlation Matrix\", fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with target variable\n",
    "print(\"\\nCorrelation with population change (sorted by absolute value):\")\n",
    "target_corr = (\n",
    "    corr_matrix[\"pop_change_pct\"]\n",
    "    .drop(\"pop_change_pct\")\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef72b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of top correlated features\n",
    "top_features = target_corr.head(6).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    axes[i].scatter(X[feature], y, alpha=0.5, s=10)\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel(\"Population Change (%)\")\n",
    "    axes[i].set_title(f\"{feature} vs Pop Change\")\n",
    "\n",
    "    # Add trend line\n",
    "    z = np.polyfit(X[feature], y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(\n",
    "        X[feature].sort_values(),\n",
    "        p(X[feature].sort_values()),\n",
    "        \"r--\",\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7738a1d9",
   "metadata": {},
   "source": [
    "## 5. Data Preparation & Train-Test Split\n",
    "\n",
    "Split data into training (75%) and testing (25%) sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (75-25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} tracts\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} tracts\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "# Feature scaling (important for some algorithms)\n",
    "# Tree-based models don't require scaling, but linear models do\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nData prepared for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edcd3b0",
   "metadata": {},
   "source": [
    "## 6. Model Training & Comparison\n",
    "\n",
    "Train multiple regression models and compare performance:\n",
    "\n",
    "- Random Forest (baseline)\n",
    "- Gradient Boosting\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=10, min_samples_split=10, random_state=42\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42\n",
    "    ),\n",
    "    \"Ridge\": Ridge(alpha=1.0),\n",
    "    \"Lasso\": Lasso(alpha=0.1),\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    # Use scaled data for linear models, original for tree-based\n",
    "    if name in [\"Ridge\", \"Lasso\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "    results[name] = {\n",
    "        \"model\": model,\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"predictions\": y_pred_test,\n",
    "    }\n",
    "\n",
    "    print(f\"  Train RÂ²: {train_r2:.4f} | Test RÂ²: {test_r2:.4f}\")\n",
    "    print(f\"  Train MAE: {train_mae:.2f} | Test MAE: {test_mae:.2f}\")\n",
    "    print(f\"  Test RMSE: {test_rmse:.2f}\\n\")\n",
    "\n",
    "print(\"âœ… All models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": list(results.keys()),\n",
    "        \"Train RÂ²\": [results[m][\"train_r2\"] for m in results.keys()],\n",
    "        \"Test RÂ²\": [results[m][\"test_r2\"] for m in results.keys()],\n",
    "        \"Test MAE\": [results[m][\"test_mae\"] for m in results.keys()],\n",
    "        \"Test RMSE\": [results[m][\"test_rmse\"] for m in results.keys()],\n",
    "    }\n",
    ")\n",
    "\n",
    "comparison_df = comparison_df.sort_values(\"Test RÂ²\", ascending=False)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RÂ² scores\n",
    "comparison_df.plot(x=\"Model\", y=[\"Train RÂ²\", \"Test RÂ²\"], kind=\"bar\", ax=axes[0])\n",
    "axes[0].set_ylabel(\"RÂ² Score\")\n",
    "axes[0].set_title(\"Model RÂ² Comparison (Higher is Better)\")\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].legend([\"Training\", \"Testing\"])\n",
    "axes[0].axhline(0.7, color=\"green\", linestyle=\"--\", alpha=0.5, label=\"Good threshold\")\n",
    "\n",
    "# MAE scores\n",
    "comparison_df.plot(x=\"Model\", y=\"Test MAE\", kind=\"bar\", ax=axes[1], color=\"coral\")\n",
    "axes[1].set_ylabel(\"Mean Absolute Error (%)\")\n",
    "axes[1].set_title(\"Model MAE Comparison (Lower is Better)\")\n",
    "axes[1].legend([\"Test MAE\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e72fa0",
   "metadata": {},
   "source": [
    "## 7. Select Best Model & Analyze Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model based on Test RÂ²\n",
    "best_model_name = comparison_df.iloc[0][\"Model\"]\n",
    "best_model_info = results[best_model_name]\n",
    "best_model = best_model_info[\"model\"]\n",
    "\n",
    "print(f\"âœ… Best Model: {best_model_name}\")\n",
    "print(f\"   Test RÂ²: {best_model_info['test_r2']:.4f}\")\n",
    "print(f\"   Test MAE: {best_model_info['test_mae']:.2f}%\")\n",
    "print(f\"   Test RMSE: {best_model_info['test_rmse']:.2f}%\")\n",
    "\n",
    "# Predicted vs Actual scatter plot\n",
    "y_pred_best = best_model_info[\"predictions\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(y_test, y_pred_best, alpha=0.5, s=30)\n",
    "axes[0].plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Perfect Prediction\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Actual Population Change (%)\")\n",
    "axes[0].set_ylabel(\"Predicted Population Change (%)\")\n",
    "axes[0].set_title(\n",
    "    f'{best_model_name}: Predicted vs Actual\\nRÂ² = {best_model_info[\"test_r2\"]:.3f}'\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - y_pred_best\n",
    "axes[1].scatter(y_pred_best, residuals, alpha=0.5, s=30)\n",
    "axes[1].axhline(0, color=\"red\", linestyle=\"--\", lw=2)\n",
    "axes[1].set_xlabel(\"Predicted Population Change (%)\")\n",
    "axes[1].set_ylabel(\"Residuals (Actual - Predicted)\")\n",
    "axes[1].set_title(f\"{best_model_name}: Residuals Plot\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(residuals, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "plt.xlabel(\"Residuals (%)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(f\"Distribution of Prediction Errors - {best_model_name}\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.2f}%\")\n",
    "print(f\"  Std: {residuals.std():.2f}%\")\n",
    "print(f\"  Median: {residuals.median():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbd847",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis\n",
    "\n",
    "Understand which features most influence population growth predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (only for tree-based models)\n",
    "if best_model_name in [\"Random Forest\", \"Gradient Boosting\"]:\n",
    "    importance = pd.DataFrame(\n",
    "        {\"Feature\": available_features, \"Importance\": best_model.feature_importances_}\n",
    "    ).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "    print(\"\\nFeature Importance (Top 10):\")\n",
    "    print(importance.head(10).to_string(index=False))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_n = 15\n",
    "    importance_top = importance.head(top_n).sort_values(\"Importance\", ascending=True)\n",
    "\n",
    "    plt.barh(importance_top[\"Feature\"], importance_top[\"Importance\"])\n",
    "    plt.xlabel(\"Importance Score\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(f\"Top {top_n} Most Important Features - {best_model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # For linear models, show coefficients\n",
    "    coef_df = pd.DataFrame(\n",
    "        {\"Feature\": available_features, \"Coefficient\": best_model.coef_}\n",
    "    )\n",
    "    coef_df[\"Abs_Coefficient\"] = coef_df[\"Coefficient\"].abs()\n",
    "    coef_df = coef_df.sort_values(\"Abs_Coefficient\", ascending=False)\n",
    "\n",
    "    print(\"\\nFeature Coefficients (Top 10 by absolute value):\")\n",
    "    print(coef_df[[\"Feature\", \"Coefficient\"]].head(10).to_string(index=False))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_n = 15\n",
    "    coef_top = coef_df.head(top_n).sort_values(\"Coefficient\", ascending=True)\n",
    "\n",
    "    colors = [\"red\" if x < 0 else \"green\" for x in coef_top[\"Coefficient\"]]\n",
    "    plt.barh(coef_top[\"Feature\"], coef_top[\"Coefficient\"], color=colors, alpha=0.7)\n",
    "    plt.xlabel(\"Coefficient Value\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.title(\n",
    "        f\"Top {top_n} Feature Coefficients - {best_model_name}\\n(Red=Negative, Green=Positive)\"\n",
    "    )\n",
    "    plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24126337",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning (Optional)\n",
    "\n",
    "Fine-tune the best model using Grid Search Cross-Validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for best model\n",
    "# WARNING: This can take several minutes!\n",
    "\n",
    "if best_model_name == \"Random Forest\":\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [8, 10, 12],\n",
    "        \"min_samples_split\": [5, 10, 15],\n",
    "        \"min_samples_leaf\": [2, 4],\n",
    "    }\n",
    "    base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "elif best_model_name == \"Gradient Boosting\":\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [200, 300, 400],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"min_samples_split\": [5, 10],\n",
    "    }\n",
    "    base_model = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "else:\n",
    "    print(f\"Skipping grid search for {best_model_name}\")\n",
    "    base_model = None\n",
    "\n",
    "if base_model is not None:\n",
    "    print(f\"Starting Grid Search for {best_model_name}...\")\n",
    "    print(f\"Testing {np.prod([len(v) for v in param_grid.values()])} combinations...\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        base_model, param_grid, cv=5, scoring=\"r2\", n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    # Use scaled or unscaled data based on model type\n",
    "    if best_model_name in [\"Ridge\", \"Lasso\"]:\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        y_pred_tuned = grid_search.predict(X_test_scaled)\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred_tuned = grid_search.predict(X_test)\n",
    "\n",
    "    print(f\"\\nâœ… Grid Search Complete!\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV RÂ²: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Evaluate tuned model\n",
    "    tuned_r2 = r2_score(y_test, y_pred_tuned)\n",
    "    tuned_mae = mean_absolute_error(y_test, y_pred_tuned)\n",
    "    tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "\n",
    "    print(f\"\\nTuned Model Performance:\")\n",
    "    print(f\"  Test RÂ²: {tuned_r2:.4f} (Before: {best_model_info['test_r2']:.4f})\")\n",
    "    print(f\"  Test MAE: {tuned_mae:.2f}% (Before: {best_model_info['test_mae']:.2f}%)\")\n",
    "    print(\n",
    "        f\"  Test RMSE: {tuned_rmse:.2f}% (Before: {best_model_info['test_rmse']:.2f}%)\"\n",
    "    )\n",
    "\n",
    "    # Update best model if improved\n",
    "    if tuned_r2 > best_model_info[\"test_r2\"]:\n",
    "        print(\"\\nâœ… Tuned model is better! Updating...\")\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_model_info[\"test_r2\"] = tuned_r2\n",
    "        best_model_info[\"test_mae\"] = tuned_mae\n",
    "        best_model_info[\"test_rmse\"] = tuned_rmse\n",
    "    else:\n",
    "        print(\"\\nOriginal model performs better. Keeping original.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45a9f7",
   "metadata": {},
   "source": [
    "## 10. Make Predictions for Future Growth (2030/2040)\n",
    "\n",
    "Use the trained model to predict future population changes for all census tracts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for all census tracts\n",
    "if best_model_name in [\"Ridge\", \"Lasso\"]:\n",
    "    df[\"predicted_growth_pct\"] = best_model.predict(\n",
    "        scaler.transform(df[available_features])\n",
    "    )\n",
    "else:\n",
    "    df[\"predicted_growth_pct\"] = best_model.predict(df[available_features])\n",
    "\n",
    "# Calculate predicted 2030 population (assuming linear growth from 2021)\n",
    "# This is a simple projection - adjust years as needed\n",
    "years_from_baseline = 9  # 2021 to 2030\n",
    "growth_factor = df[\"predicted_growth_pct\"] / 100  # Convert % to decimal\n",
    "df[\"predicted_pop_2030\"] = df[\"pop_2021\"] * (\n",
    "    1 + growth_factor * (years_from_baseline / 11)\n",
    ")\n",
    "\n",
    "# Calculate predicted 2040 population\n",
    "years_from_baseline_2040 = 19  # 2021 to 2040\n",
    "df[\"predicted_pop_2040\"] = df[\"pop_2021\"] * (\n",
    "    1 + growth_factor * (years_from_baseline_2040 / 11)\n",
    ")\n",
    "\n",
    "print(\"Predictions generated for all census tracts!\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(\n",
    "    df[\n",
    "        [\n",
    "            \"pop_2010\",\n",
    "            \"pop_2021\",\n",
    "            \"predicted_growth_pct\",\n",
    "            \"predicted_pop_2030\",\n",
    "            \"predicted_pop_2040\",\n",
    "        ]\n",
    "    ].head(10)\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nPredicted Growth Distribution:\")\n",
    "print(f\"  Mean growth: {df['predicted_growth_pct'].mean():.2f}%\")\n",
    "print(f\"  Median growth: {df['predicted_growth_pct'].median():.2f}%\")\n",
    "print(f\"  Std dev: {df['predicted_growth_pct'].std():.2f}%\")\n",
    "print(f\"  Min: {df['predicted_growth_pct'].min():.2f}%\")\n",
    "print(f\"  Max: {df['predicted_growth_pct'].max():.2f}%\")\n",
    "\n",
    "# Categorize predictions\n",
    "df[\"growth_category\"] = pd.cut(\n",
    "    df[\"predicted_growth_pct\"],\n",
    "    bins=[-np.inf, -5, 5, 15, np.inf],\n",
    "    labels=[\"Declining\", \"Stable\", \"Growing\", \"Rapid Growth\"],\n",
    ")\n",
    "\n",
    "print(f\"\\nPredicted Growth Categories:\")\n",
    "print(df[\"growth_category\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5003c82",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0759380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population projections over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Total population projection\n",
    "total_2010 = df[\"pop_2010\"].sum()\n",
    "total_2021 = df[\"pop_2021\"].sum()\n",
    "total_2030 = df[\"predicted_pop_2030\"].sum()\n",
    "total_2040 = df[\"predicted_pop_2040\"].sum()\n",
    "\n",
    "years = [2010, 2021, 2030, 2040]\n",
    "totals = [total_2010, total_2021, total_2030, total_2040]\n",
    "\n",
    "axes[0].plot(years, totals, marker=\"o\", linewidth=2, markersize=10, color=\"steelblue\")\n",
    "axes[0].scatter(\n",
    "    [2010, 2021],\n",
    "    [total_2010, total_2021],\n",
    "    s=100,\n",
    "    color=\"green\",\n",
    "    label=\"Actual\",\n",
    "    zorder=5,\n",
    ")\n",
    "axes[0].scatter(\n",
    "    [2030, 2040],\n",
    "    [total_2030, total_2040],\n",
    "    s=100,\n",
    "    color=\"orange\",\n",
    "    label=\"Predicted\",\n",
    "    zorder=5,\n",
    ")\n",
    "axes[0].set_xlabel(\"Year\")\n",
    "axes[0].set_ylabel(\"Total Population\")\n",
    "axes[0].set_title(\"Harris County Total Population Projection\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].ticklabel_format(style=\"plain\", axis=\"y\")\n",
    "\n",
    "# Growth rate comparison\n",
    "axes[1].scatter(df[\"pop_change_pct\"], df[\"predicted_growth_pct\"], alpha=0.5, s=30)\n",
    "axes[1].plot(\n",
    "    [df[\"pop_change_pct\"].min(), df[\"pop_change_pct\"].max()],\n",
    "    [df[\"pop_change_pct\"].min(), df[\"pop_change_pct\"].max()],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"1:1 Line\",\n",
    ")\n",
    "axes[1].set_xlabel(\"Actual Growth 2010-2021 (%)\")\n",
    "axes[1].set_ylabel(\"Predicted Growth (%)\")\n",
    "axes[1].set_title(\"Actual vs Predicted Growth Patterns\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Harris County Population Projections:\")\n",
    "print(f\"  2010 (actual): {total_2010:,.0f}\")\n",
    "print(f\"  2021 (actual): {total_2021:,.0f}\")\n",
    "print(f\"  2030 (predicted): {total_2030:,.0f}\")\n",
    "print(f\"  2040 (predicted): {total_2040:,.0f}\")\n",
    "print(f\"\\n  Change 2010-2021: {((total_2021-total_2010)/total_2010*100):.1f}%\")\n",
    "print(f\"  Predicted change 2021-2030: {((total_2030-total_2021)/total_2021*100):.1f}%\")\n",
    "print(f\"  Predicted change 2021-2040: {((total_2040-total_2021)/total_2021*100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6f120",
   "metadata": {},
   "source": [
    "## 12. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_cols = [\n",
    "    \"tract_id\",\n",
    "    \"pop_2010\",\n",
    "    \"pop_2021\",\n",
    "    \"pop_change_pct\",\n",
    "    \"predicted_growth_pct\",\n",
    "    \"predicted_pop_2030\",\n",
    "    \"predicted_pop_2040\",\n",
    "    \"growth_category\",\n",
    "    \"pct_in_AE\",\n",
    "    \"elev_mean\",\n",
    "    \"dist_water_m\",\n",
    "]\n",
    "\n",
    "# Adjust columns based on what's actually in your dataframe\n",
    "available_output_cols = [col for col in output_cols if col in df.columns]\n",
    "\n",
    "df[available_output_cols].to_csv(\n",
    "    \"../data/processed/census_predictions.csv\", index=False\n",
    ")\n",
    "print(\"âœ… Predictions saved to: ../data/processed/census_predictions.csv\")\n",
    "\n",
    "# Save model performance metrics\n",
    "metrics_summary = {\n",
    "    \"Best Model\": best_model_name,\n",
    "    \"Test RÂ²\": best_model_info[\"test_r2\"],\n",
    "    \"Test MAE (%)\": best_model_info[\"test_mae\"],\n",
    "    \"Test RMSE (%)\": best_model_info[\"test_rmse\"],\n",
    "    \"Number of Features\": len(available_features),\n",
    "    \"Training Size\": len(X_train),\n",
    "    \"Test Size\": len(X_test),\n",
    "    \"Total Tracts\": len(df),\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_summary])\n",
    "metrics_df.to_csv(\"../data/processed/model_performance.csv\", index=False)\n",
    "print(\"âœ… Model metrics saved to: ../data/processed/model_performance.csv\")\n",
    "\n",
    "# Optional: Save the model for future use\n",
    "# import joblib\n",
    "# joblib.dump(best_model, '../models/population_growth_model.pkl')\n",
    "# joblib.dump(scaler, '../models/scaler.pkl')\n",
    "# print(\"âœ… Model saved to: ../models/population_growth_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731c7d4",
   "metadata": {},
   "source": [
    "## 13. Key Findings Summary\n",
    "\n",
    "**Regression Problem**: Predict % population change for Harris County census tracts\n",
    "\n",
    "**Target Variable (Y)**:\n",
    "\n",
    "- `pop_change_pct` = ((pop_2021 - pop_2010) / pop_2010) Ã— 100\n",
    "\n",
    "**Key Features (X)**:\n",
    "\n",
    "- Flood risk metrics (% in AE zone, X zone, etc.)\n",
    "- Elevation & topography (mean, slope, terrain roughness)\n",
    "- Hydrological features (distance to water, flow accumulation, REM)\n",
    "- Baseline demographics (2010 population, density)\n",
    "\n",
    "**Model Performance**:\n",
    "\n",
    "- Algorithm used will be displayed after running Section 6\n",
    "- Test RÂ² score indicates model's predictive accuracy\n",
    "- MAE shows average prediction error in percentage points\n",
    "\n",
    "**Next Steps**:\n",
    "\n",
    "1. Run this notebook with your processed CSV data\n",
    "2. Analyze which features most influence growth\n",
    "3. Use predictions to identify high-growth and declining areas\n",
    "4. Overlay with flood risk maps for planning insights\n",
    "5. Consider climate scenarios and infrastructure changes for future refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1629cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of predicted growth\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(\n",
    "    df[\"predicted_growth_pct\"], bins=50, edgecolor=\"black\", alpha=0.7, color=\"steelblue\"\n",
    ")\n",
    "plt.axvline(0, color=\"red\", linestyle=\"--\", linewidth=2, label=\"No Change\")\n",
    "plt.axvline(\n",
    "    df[\"predicted_growth_pct\"].mean(),\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f'Mean: {df[\"predicted_growth_pct\"].mean():.1f}%',\n",
    ")\n",
    "plt.xlabel(\"Predicted Population Growth (%)\")\n",
    "plt.ylabel(\"Number of Census Tracts\")\n",
    "plt.title(\"Distribution of Predicted Growth Rates\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "growth_counts = df[\"growth_category\"].value_counts()\n",
    "colors_cat = [\"red\", \"yellow\", \"lightgreen\", \"darkgreen\"]\n",
    "plt.bar(\n",
    "    growth_counts.index,\n",
    "    growth_counts.values,\n",
    "    color=colors_cat,\n",
    "    alpha=0.7,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.ylabel(\"Number of Census Tracts\")\n",
    "plt.title(\"Census Tracts by Growth Category\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of predicted growth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(\n",
    "    df[\"predicted_growth_pct\"], bins=50, edgecolor=\"black\", alpha=0.7, color=\"steelblue\"\n",
    ")\n",
    "axes[0].axvline(\n",
    "    df[\"predicted_growth_pct\"].mean(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=f'Mean: {df[\"predicted_growth_pct\"].mean():.1f}%',\n",
    ")\n",
    "axes[0].axvline(0, color=\"black\", linestyle=\"-\", linewidth=1, alpha=0.5)\n",
    "axes[0].set_xlabel(\"Predicted Growth (%)\")\n",
    "axes[0].set_ylabel(\"Number of Census Tracts\")\n",
    "axes[0].set_title(\"Distribution of Predicted Population Growth\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Growth categories\n",
    "df[\"growth_category\"].value_counts().plot(kind=\"bar\", ax=axes[1], color=\"coral\")\n",
    "axes[1].set_xlabel(\"Growth Category\")\n",
    "axes[1].set_ylabel(\"Number of Census Tracts\")\n",
    "axes[1].set_title(\"Census Tracts by Predicted Growth Category\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
